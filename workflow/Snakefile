#### ----------------------- Imports ----------------------- ####

import pandas as pd 
from os.path import join

#### -------------------- Configuration -------------------- ####

configfile: "config.yml"

#### ------------------------ Input ------------------------ ####

# Read in the barcode runs 
barcode_runs = pd.read_csv(config["barcode_runs"])

# Check for the necessary columns
required_columns = {
    "date",
    "plate",
    "library",
    "standard_set",
    "fastq",
}
required_columns.update(config["id_columns"])
missing_columns = required_columns - set(barcode_runs.columns)
if missing_columns:
    raise ValueError(
        f"The following columns must exist in the `barcode_runs` dataframe: {list(missing_columns)}"
    )

# Make the 'sample' column using the id columns
if "sample" in barcode_runs.columns:
    raise ValueError(
        f"The `barcode_runs` dataframe already has a column called 'sample', please rename the column or remove it."
    )
barcode_runs["sample"] = barcode_runs[config["id_columns"]].apply(
    lambda x: "-".join(x.astype(str)), axis=1
)

# Check that the sample names are unique
if len(barcode_runs["sample"].unique()) != len(barcode_runs):
    raise ValueError(f"The sample names derived from the provided id columns are not unique.")


# Check that the neutralization standard file has the 'barcode' and 'standard_set' columns
standards_required_columns = {"barcode", "standard_set"}
standards_missing_columns = standards_required_columns - set(pd.read_csv(config["neut_standards"]).columns)
if standards_missing_columns:
    raise ValueError(
        f"The following columns must exist in the `neut_standards` dataframe: {list(standards_missing_columns)}"
    )

# Check that the strain to barcode file has the 'strain', 'barcode' and 'library' columns
library_required_columns = {"strain", "barcode", "library"}
library_missing_columns = library_required_columns - set(pd.read_csv(config["strain_to_barcode"]).columns)
if library_missing_columns:
    raise ValueError(
        f"The following columns must exist in the `strain_to_barcode` dataframe: {list(library_missing_columns)}"
    )


# Get a list of the sample names
samples = barcode_runs["sample"].unique().tolist()
# Get a list of plate names
plates = barcode_runs["plate"].unique().tolist()

#### ----------------------- Targets ----------------------- ####

rule all:
    input: 
        expand(join(config["selection_dir"], "{plate}", "{plate}_fractioninfectivity.csv"), plate = plates)


#### ------------------------ Rules ------------------------ ####

rule clean:
    shell:
        """
        rm -rf logs/
        rm -rf tmp/
        rm -f slurm*.out
        """

rule count_barcodes:
    """Count barcodes for each sample."""
    input:
        fastq=lambda wildcards: barcode_runs.set_index("sample").at[wildcards.sample, "fastq"],
        variants=config["strain_to_barcode"],
        standards=config["neut_standards"],
    output:
        counts=join(config["barcode_counts_dir"], "{sample}", "{sample}_counts.csv"),
        invalid=join(config["barcode_counts_dir"], "{sample}", "{sample}_invalid.csv"),
        fates=join(config["barcode_counts_dir"], "{sample}", "{sample}_fates.csv"),
    params:
        library=lambda wildcards: barcode_runs.set_index("sample").at[wildcards.sample, "library"],
        standard_set=lambda wildcards: barcode_runs.set_index("sample").at[wildcards.sample, "standard_set"],
        parser_params=config["illumina_barcode_parser_params"]
    conda:
        "envs/count_barcodes.yml"
    log:
        join(config["barcode_counts_dir"], "{sample}", "count_barcodes.log")
    script:
        "scripts/count_barcodes.py"


rule analyze_barcode_counts:
    """Process barcode counts and perform basic quality control."""
    input:
        counts=expand(join(config["barcode_counts_dir"], "{sample}", "{sample}_counts.csv"), sample = samples),
        invalid=expand(join(config["barcode_counts_dir"], "{sample}", "{sample}_invalid.csv"), sample = samples),
        fates=expand(join(config["barcode_counts_dir"], "{sample}", "{sample}_fates.csv"), sample = samples),
        ipynb="workflow/notebooks/analyze-barcode-counts.ipynb"
    output:
        ipynb=join(config["notebook_dir"], "analyze-barcode-counts.ipynb"),
        html=join(config["notebook_dir"], "analyze-barcode-counts.html"),
        joined_counts=join(config["barcode_counts_dir"], "barcode_counts.csv"),
    conda:
        "envs/count_barcodes.yml"
    log:
        join(config["notebook_dir"], "logs", "analyze-barcode-counts.log")
    shell:
        """
        papermill {input.ipynb} {output.ipynb} \
            -p joined_counts {output.joined_counts} \
            -p snakemake True \
            &> {log}

        jupyter nbconvert --to html {output.ipynb}
        """

rule calculate_fraction_infectivity:
    """Process counts files by plate and calculate fraction infectivity."""
    input:
        variants=config["strain_to_barcode"],
        standards=config["neut_standards"],
        counts=expand(join(config["barcode_counts_dir"], "{plate}_barcode_counts.csv"), plate = plates),
    output:
        fraction_infectivity=join(config["selection_dir"], "{plate}", "{plate}_fractioninfectivity.csv"),
    log:
        join(config["selection_dir"], "{plate}", "fraction-infectivity.log")
    script:
        "scripts/calculate_fraction_infectivity-perplate.py"



